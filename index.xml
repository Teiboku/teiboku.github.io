<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>かんそう</title><link>https://teiboku.github.io/</link><description>Recent content on かんそう</description><generator>Hugo -- gohugo.io</generator><language>ja</language><lastBuildDate>Sat, 18 Oct 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://teiboku.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>CLIPに基づく雨水パターン認識による画像除雨モデル</title><link>https://teiboku.github.io/projects/1760784774221-clip%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E9%9B%A8%E6%B0%B4%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3%E8%AA%8D%E8%AD%98%E3%81%AB%E3%82%88%E3%82%8B%E7%94%BB%E5%83%8F%E9%99%A4%E9%9B%A8%E3%83%A2%E3%83%87%E3%83%AB/</link><pubDate>Sat, 18 Oct 2025 00:00:00 +0000</pubDate><guid>https://teiboku.github.io/projects/1760784774221-clip%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%8F%E9%9B%A8%E6%B0%B4%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3%E8%AA%8D%E8%AD%98%E3%81%AB%E3%82%88%E3%82%8B%E7%94%BB%E5%83%8F%E9%99%A4%E9%9B%A8%E3%83%A2%E3%83%87%E3%83%AB/</guid><description>A derain model use CLIP to auto routing.</description></item><item><title>DM³Net: デュアルカメラ超解像の新アプローチ</title><link>https://teiboku.github.io/projects/1760786004876-%E3%83%87%E3%83%A5%E3%82%A2%E3%83%AB%E3%82%AB%E3%83%A1%E3%83%A9%E7%94%BB%E5%83%8F%E3%81%AB%E5%AF%BE%E3%81%99%E3%82%8B%E8%B6%85%E8%A7%A3%E5%83%8F%E6%89%8B%E6%B3%95/</link><pubDate>Sat, 18 Oct 2025 00:00:00 +0000</pubDate><guid>https://teiboku.github.io/projects/1760786004876-%E3%83%87%E3%83%A5%E3%82%A2%E3%83%AB%E3%82%AB%E3%83%A1%E3%83%A9%E7%94%BB%E5%83%8F%E3%81%AB%E5%AF%BE%E3%81%99%E3%82%8B%E8%B6%85%E8%A7%A3%E5%83%8F%E6%89%8B%E6%B3%95/</guid><description>スマートフォンの複眼カメラを活用した高精細画像生成技術 DM³Net の紹介</description></item><item><title>Efficient Hybrid Zoom using Camera Fusion on Mobile Phones Reading Notes</title><link>https://teiboku.github.io/posts/ehz/</link><pubDate>Wed, 15 Jan 2025 00:00:00 +0000</pubDate><guid>https://teiboku.github.io/posts/ehz/</guid><description>&lt;h2 class="relative group"&gt;Abstract
&lt;div id="abstract" class="anchor"&gt;&lt;/div&gt;
&lt;span
class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"&gt;
&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href="#abstract" aria-label="アンカー"&gt;#&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;DSLR cameras can achieve various zoom levels by changing the lens distance or swapping lens types. However, due to space constraints, these techniques are not feasible on mobile devices. Most smartphones adopt a &lt;strong&gt;hybrid zoom system&lt;/strong&gt;: typically using a wide-angle (W) camera for low zoom levels and a telephoto (T) camera for high zoom levels. To simulate zoom levels between W and T, these systems crop and digitally enlarge images from W, resulting in significant detail loss. In this paper, we propose an efficient hybrid zoom super-resolution system for mobile devices. This system captures &lt;strong&gt;synchronized W and T image pairs&lt;/strong&gt; and &lt;strong&gt;utilizes a machine learning model to align and transfer details from T to W&lt;/strong&gt;. We further develop an &lt;strong&gt;adaptive blending method&lt;/strong&gt; that can handle &lt;strong&gt;depth of field mismatches, scene occlusions, motion uncertainties, and alignment errors&lt;/strong&gt;. To minimize domain differences, we design a dual smartphone camera setup to capture real scene inputs and real label data for supervised training. In extensive evaluations on real scenes, our method can generate 12-megapixel images on mobile platforms in 500 milliseconds, achieving TA.&lt;/p&gt;</description></item><item><title>モデルリリースパイプライン</title><link>https://teiboku.github.io/projects/1736923185327-a-model-release-pipeline/</link><pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate><guid>https://teiboku.github.io/projects/1736923185327-a-model-release-pipeline/</guid><description>セマンティック検索のためのモデルリリースパイプライン</description></item><item><title>AWS OpenSearchにおける二相ニューラルスパース検索</title><link>https://teiboku.github.io/projects/1736922318122-neural-sparse-search-on-aws-opensearch/</link><pubDate>Sun, 15 Jan 2023 00:00:00 +0000</pubDate><guid>https://teiboku.github.io/projects/1736922318122-neural-sparse-search-on-aws-opensearch/</guid><description>AWS OpenSearchにおける二相ニューラルスパース検索</description></item><item><title>D5 Render-Rhino 同期プラグイン</title><link>https://teiboku.github.io/projects/1735963425218-d5-render-rhino-sync-plugin/</link><pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate><guid>https://teiboku.github.io/projects/1735963425218-d5-render-rhino-sync-plugin/</guid><description>D5 RenderとRhinoの同期プラグイン</description></item><item><title>Kansouの履歴書</title><link>https://teiboku.github.io/resume/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://teiboku.github.io/resume/</guid><description>&lt;iframe
src="https://teiboku.github.io/resume/congguan_jp.pdf"
width="200%"
height="800px"
&gt;
お使いのブラウザはPDFの埋め込みに対応していません。
&lt;a href="https://teiboku.github.io/resume/congguan_jp.pdf"&gt;こちらからダウンロード&lt;/a&gt;してください。
&lt;/iframe&gt;</description></item></channel></rss>